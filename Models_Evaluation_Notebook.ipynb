{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ctEnCtHzKwx"
      },
      "source": [
        "# Models Evaluation Notebook\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1WXxXUT_6_a"
      },
      "source": [
        "Mount Google Drive to access your data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOOfjmRD_ppM",
        "outputId": "ae728f0d-adfa-459a-cd6f-b9a33b112a6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jByfpneRc97"
      },
      "source": [
        "Install necessary notebooks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIbY0gCaRvMU"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -e git+https://github.com/ncullen93/torchsample.git#egg=torchsample\n",
        "!pip install visdom\n",
        "!pip install nibabel\n",
        "!pip install h5py\n",
        "!pip install torchsample\n",
        "!pip install tensorboardX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd-SNRHQbNB7"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoOPghzXShT1",
        "outputId": "72afea1b-335e-47f5-cf16-47855138dcf7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x793516eec0f0>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#import all libraries\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import pandas as pd\n",
        "from torch.autograd import Variable\n",
        "# from src.torchsample.torchsample.transforms import RandomRotate, RandomTranslate, RandomFlip, ToTensor, Compose, RandomAffine\n",
        "# from torchvision import transforms\n",
        "import torchvision.transforms as transforms\n",
        "from tensorboardX import SummaryWriter\n",
        "import math\n",
        "from sklearn import metrics\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from datetime import datetime\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKghU1LRCHNW"
      },
      "source": [
        "Assign Device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhS5Z06JCK2A",
        "outputId": "3d43c94a-15d2-4fe7-9448-1921e4323795"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOLCnvQ4HUd2"
      },
      "source": [
        "Create Dataloader\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQzFc45wHOwX"
      },
      "outputs": [],
      "source": [
        "class Dataset(data.Dataset):\n",
        "    def __init__(self, root_dir, task, plane, split='train', transform=None):\n",
        "        super().__init__()\n",
        "        self.task = task\n",
        "        self.plane = plane\n",
        "        self.root_dir = root_dir\n",
        "        self.split=split\n",
        "        if self.split == 'train':\n",
        "            self.folder_path = self.root_dir + 'train/{0}/'.format(plane)\n",
        "            self.records = pd.read_csv(\n",
        "                self.root_dir + 'train-{0}.csv'.format(task), header=None, names=['id', 'label'])\n",
        "        elif self.split == 'test':\n",
        "            self.folder_path = self.root_dir + 'test/{0}/'.format(plane)\n",
        "            self.records = pd.read_csv(\n",
        "                self.root_dir + 'test-{0}.csv'.format(task), header=None, names=['id', 'label'])\n",
        "        else:\n",
        "            self.folder_path = self.root_dir + 'valid/{0}/'.format(plane)\n",
        "\n",
        "            self.records = pd.read_csv(\n",
        "                self.root_dir + 'valid-{0}.csv'.format(task), header=None, names=['id', 'label'])\n",
        "\n",
        "        self.records['id'] = self.records['id'].map(\n",
        "            lambda i: '0' * (4 - len(str(i))) + str(i))\n",
        "        self.paths = [self.folder_path + filename +\n",
        "                      '.npy' for filename in self.records['id'].tolist()]\n",
        "        self.labels = self.records['label'].tolist()\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "        pos = np.sum(self.labels)\n",
        "        neg = len(self.labels) - pos\n",
        "        self.weights = [1, neg / pos]\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        array = np.load(self.paths[index]) #load MRI\n",
        "        label = self.labels[index] #get label of MRI\n",
        "        label = torch.FloatTensor([label]) #convert type from numpy to torch\n",
        "\n",
        "        if self.transform: #if you are transforming it\n",
        "            array = self.transform(array) #transform the image\n",
        "            array = array.numpy()\n",
        "\n",
        "\n",
        "        array = np.stack((array,)*3, axis=1) #the model expects dimensions of (3, 256, 256), the MRIs are greyscale of size (256, 256). Therefore, we stack the image three times to fit the dimensions for the model.\n",
        "        array = torch.FloatTensor(array)\n",
        "\n",
        "        if label.item() == 1:\n",
        "            weight = np.array([self.weights[1]])\n",
        "            weight = torch.FloatTensor(weight)\n",
        "        else:\n",
        "            weight = np.array([self.weights[0]])\n",
        "            weight = torch.FloatTensor(weight)\n",
        "\n",
        "        return array, label, weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40GEJprzKTES"
      },
      "source": [
        "## Define models to be evaluated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMkWUr5mzEUT"
      },
      "outputs": [],
      "source": [
        "#add another fully connected layer to convert output (1,1000) to (1)\n",
        "class BaselineNetAdapt(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.pretrained_model = nn.Sequential(*list(models.resnet18(weights='ResNet18_Weights.DEFAULT').children())[:-2])\n",
        "        self.conv1 = nn.Conv2d(512,64,4)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.conv2 = nn.Conv2d(64,32,4)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.classifer = nn.Linear(32,1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # input size of x (1, s, 3, 256, 256) where s is the number of slices in one MRI\n",
        "        x = torch.squeeze(x, dim=0) #output size (s, 3, 256, 256)\n",
        "        x = self.pretrained_model(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = nn.functional.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = nn.functional.relu(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = self.flatten(x)\n",
        "\n",
        "        output = torch.max(x, 0, keepdim=True)[0] #output size (1, 1000)\n",
        "        output =nn.ReLU()(output)\n",
        "        output = self.classifer(output) #output size (1)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIWozW60zJRg",
        "outputId": "73112672-fbb2-4230-be57-7a8cc42e051e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 61.8MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 128, 128]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 128, 128]             128\n",
            "              ReLU-3         [-1, 64, 128, 128]               0\n",
            "         MaxPool2d-4           [-1, 64, 64, 64]               0\n",
            "            Conv2d-5           [-1, 64, 64, 64]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 64, 64]             128\n",
            "              ReLU-7           [-1, 64, 64, 64]               0\n",
            "            Conv2d-8           [-1, 64, 64, 64]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 64, 64]             128\n",
            "             ReLU-10           [-1, 64, 64, 64]               0\n",
            "       BasicBlock-11           [-1, 64, 64, 64]               0\n",
            "           Conv2d-12           [-1, 64, 64, 64]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 64, 64]             128\n",
            "             ReLU-14           [-1, 64, 64, 64]               0\n",
            "           Conv2d-15           [-1, 64, 64, 64]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 64, 64]             128\n",
            "             ReLU-17           [-1, 64, 64, 64]               0\n",
            "       BasicBlock-18           [-1, 64, 64, 64]               0\n",
            "           Conv2d-19          [-1, 128, 32, 32]          73,728\n",
            "      BatchNorm2d-20          [-1, 128, 32, 32]             256\n",
            "             ReLU-21          [-1, 128, 32, 32]               0\n",
            "           Conv2d-22          [-1, 128, 32, 32]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 32, 32]             256\n",
            "           Conv2d-24          [-1, 128, 32, 32]           8,192\n",
            "      BatchNorm2d-25          [-1, 128, 32, 32]             256\n",
            "             ReLU-26          [-1, 128, 32, 32]               0\n",
            "       BasicBlock-27          [-1, 128, 32, 32]               0\n",
            "           Conv2d-28          [-1, 128, 32, 32]         147,456\n",
            "      BatchNorm2d-29          [-1, 128, 32, 32]             256\n",
            "             ReLU-30          [-1, 128, 32, 32]               0\n",
            "           Conv2d-31          [-1, 128, 32, 32]         147,456\n",
            "      BatchNorm2d-32          [-1, 128, 32, 32]             256\n",
            "             ReLU-33          [-1, 128, 32, 32]               0\n",
            "       BasicBlock-34          [-1, 128, 32, 32]               0\n",
            "           Conv2d-35          [-1, 256, 16, 16]         294,912\n",
            "      BatchNorm2d-36          [-1, 256, 16, 16]             512\n",
            "             ReLU-37          [-1, 256, 16, 16]               0\n",
            "           Conv2d-38          [-1, 256, 16, 16]         589,824\n",
            "      BatchNorm2d-39          [-1, 256, 16, 16]             512\n",
            "           Conv2d-40          [-1, 256, 16, 16]          32,768\n",
            "      BatchNorm2d-41          [-1, 256, 16, 16]             512\n",
            "             ReLU-42          [-1, 256, 16, 16]               0\n",
            "       BasicBlock-43          [-1, 256, 16, 16]               0\n",
            "           Conv2d-44          [-1, 256, 16, 16]         589,824\n",
            "      BatchNorm2d-45          [-1, 256, 16, 16]             512\n",
            "             ReLU-46          [-1, 256, 16, 16]               0\n",
            "           Conv2d-47          [-1, 256, 16, 16]         589,824\n",
            "      BatchNorm2d-48          [-1, 256, 16, 16]             512\n",
            "             ReLU-49          [-1, 256, 16, 16]               0\n",
            "       BasicBlock-50          [-1, 256, 16, 16]               0\n",
            "           Conv2d-51            [-1, 512, 8, 8]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 8, 8]           1,024\n",
            "             ReLU-53            [-1, 512, 8, 8]               0\n",
            "           Conv2d-54            [-1, 512, 8, 8]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 8, 8]           1,024\n",
            "           Conv2d-56            [-1, 512, 8, 8]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 8, 8]           1,024\n",
            "             ReLU-58            [-1, 512, 8, 8]               0\n",
            "       BasicBlock-59            [-1, 512, 8, 8]               0\n",
            "           Conv2d-60            [-1, 512, 8, 8]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 8, 8]           1,024\n",
            "             ReLU-62            [-1, 512, 8, 8]               0\n",
            "           Conv2d-63            [-1, 512, 8, 8]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 8, 8]           1,024\n",
            "             ReLU-65            [-1, 512, 8, 8]               0\n",
            "       BasicBlock-66            [-1, 512, 8, 8]               0\n",
            "           Conv2d-67             [-1, 64, 5, 5]         524,352\n",
            "      BatchNorm2d-68             [-1, 64, 5, 5]             128\n",
            "           Conv2d-69             [-1, 32, 2, 2]          32,800\n",
            "AdaptiveAvgPool2d-70             [-1, 32, 1, 1]               0\n",
            "          Flatten-71                   [-1, 32]               0\n",
            "           Linear-72                    [-1, 1]              33\n",
            "================================================================\n",
            "Total params: 11,733,825\n",
            "Trainable params: 11,733,825\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.75\n",
            "Forward/backward pass size (MB): 82.03\n",
            "Params size (MB): 44.76\n",
            "Estimated Total Size (MB): 127.54\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "ResNet18Adapt_model = BaselineNetAdapt().to(device)\n",
        "ResNet18Adapt_model.name = 'ResNet18Adapt' # For evaluation\n",
        "summary(ResNet18Adapt_model, (3, 256, 256))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBqk4KS7fzk_"
      },
      "outputs": [],
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.pretrained_model = models.alexnet(pretrained=False)\n",
        "        self.pooling_layer = nn.AdaptiveAvgPool2d(1)\n",
        "        self.classifer = nn.Linear(256, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.squeeze(x, dim=0)\n",
        "        features = self.pretrained_model.features(x)\n",
        "        pooled_features = self.pooling_layer(features)\n",
        "        pooled_features = pooled_features.view(pooled_features.size(0), -1)\n",
        "        flattened_features = torch.max(pooled_features, 0, keepdim=True)[0]\n",
        "        output = self.classifer(flattened_features)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6EeRj6pdBIk",
        "outputId": "458409f7-7be9-4579-b82a-6f87ef75db35"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 63, 63]          23,296\n",
            "              ReLU-2           [-1, 64, 63, 63]               0\n",
            "         MaxPool2d-3           [-1, 64, 31, 31]               0\n",
            "            Conv2d-4          [-1, 192, 31, 31]         307,392\n",
            "              ReLU-5          [-1, 192, 31, 31]               0\n",
            "         MaxPool2d-6          [-1, 192, 15, 15]               0\n",
            "            Conv2d-7          [-1, 384, 15, 15]         663,936\n",
            "              ReLU-8          [-1, 384, 15, 15]               0\n",
            "            Conv2d-9          [-1, 256, 15, 15]         884,992\n",
            "             ReLU-10          [-1, 256, 15, 15]               0\n",
            "           Conv2d-11          [-1, 256, 15, 15]         590,080\n",
            "             ReLU-12          [-1, 256, 15, 15]               0\n",
            "        MaxPool2d-13            [-1, 256, 7, 7]               0\n",
            "AdaptiveAvgPool2d-14            [-1, 256, 1, 1]               0\n",
            "           Linear-15                    [-1, 1]             257\n",
            "================================================================\n",
            "Total params: 2,469,953\n",
            "Trainable params: 2,469,953\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.75\n",
            "Forward/backward pass size (MB): 10.66\n",
            "Params size (MB): 9.42\n",
            "Estimated Total Size (MB): 20.84\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "AlexNet_model = AlexNet().to(device)\n",
        "AlexNet_model.name = 'alexnet' # For evaluation\n",
        "summary(AlexNet_model, (3, 256, 256))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_X7jELoDZvA"
      },
      "source": [
        "Define Evaluation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-vq6WtM38NH"
      },
      "outputs": [],
      "source": [
        "def test(model,test_loader):\n",
        "    _ = model.eval()\n",
        "    y_trues = []\n",
        "    aucs = []\n",
        "    accuracys = []\n",
        "    y_preds = []\n",
        "    y_ps = []\n",
        "    running_accuracy = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (image, label, weight) in enumerate(test_loader):\n",
        "          #print(\"i = \",i)\n",
        "          if torch.cuda.is_available():\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "          label = label[0]\n",
        "          #prediction = model.forward(image.float()).squeeze(0)\n",
        "          prediction = model(image.float().squeeze(0))\n",
        "          #print(label,prediction)\n",
        "\n",
        "          probas = torch.sigmoid(prediction)\n",
        "          #print('probas:', probas.item())\n",
        "\n",
        "          preds = (prediction>0.5).float()\n",
        "          preds_arr = (preds.detach().cpu().numpy()).flatten()\n",
        "          y_ps.append(preds_arr)\n",
        "          y_trues.append(int(label[0]))\n",
        "          y_preds.append(probas[0].item())\n",
        "\n",
        "          #print(\"preds \",preds)\n",
        "          #print(\"preds_arr \",preds_arr)\n",
        "          #print(\"y_ps \",y_ps)\n",
        "          #print(\"y preds \",y_preds)\n",
        "          #print(\"y trues \",y_trues)\n",
        "\n",
        "          try:\n",
        "            #auc = metrics.roc_auc_score(int(label[0]), probas.item().to_array())\n",
        "            auc = metrics.roc_auc_score(y_trues, y_preds)\n",
        "            accuracy = metrics.accuracy_score(y_trues, y_ps)\n",
        "            #roc = metrics.roc_curve(y_trues, y_ps) # nice to have ??????????????????????????????????????\n",
        "          except Exception as e:\n",
        "            #print('Exception:', e)\n",
        "            auc = 0.5\n",
        "            accuracy = 0.5\n",
        "            #roc = 0.5\n",
        "          aucs.append(auc)\n",
        "          #print(\"roc \",roc)\n",
        "          accuracys.append(accuracy)\n",
        "          writer.add_scalar('Test/AUC', auc, i)\n",
        "          writer.add_scalar('Test/Accuracy', accuracy, i)\n",
        "          #writer.add_scalar('Test/ROC', roc, i)\n",
        "    auc_average = sum(aucs)/len(aucs)\n",
        "    acc_average = sum(accuracys)/len(accuracys)\n",
        "\n",
        "    return auc_average, acc_average"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpbrPGXeEUY8"
      },
      "source": [
        "Activate TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtyiTFWzEYFh"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zGTwQwPbmdh"
      },
      "source": [
        "Define variables to summarize the evaluation results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_5PZetsEiiL"
      },
      "outputs": [],
      "source": [
        "history_auc = {'res_net_axial': 0,'res_net_coronal': 0,'res_net_sagital': 0,'Alex_net_axial': 0,'Alex_net_coronal': 0,'Alex_net_sagital': 0}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSdEa62KqLDO"
      },
      "outputs": [],
      "source": [
        "history_acc = {'res_net_axial': 0,'res_net_coronal': 0,'res_net_sagital': 0,'Alex_net_axial': 0,'Alex_net_coronal': 0,'Alex_net_sagital': 0}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmdSilgwDgdR"
      },
      "source": [
        "## Evaluate models\n",
        "\n",
        "### ResNet 18 Adapt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYz-oD37b7LZ"
      },
      "source": [
        "Evaluation for ACL tear and Axial plane"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaBdZisrCo0R"
      },
      "outputs": [],
      "source": [
        "directory = '/content/gdrive/Shareddrives/MRNet Project/MRNet-v1.0/MRNet-v1.0/'\n",
        "task = 'acl'\n",
        "plane = 'axial' # Coronal #\n",
        "# initialise the train and validation datasets (class we defined earlier) and then initialise a Pytorch's dataloader\n",
        "test_dataset = Dataset(directory, task, plane, split='test', transform = None)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=-True, num_workers=2, drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZ-dX-EKz5__",
        "outputId": "e66cf7e3-6582-47ec-a216-4ae714a23a0d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ResNet18Adapt_model.load_state_dict(torch.load(\"/content/gdrive/Shareddrives/MRNet Project/model_weights/ResNet18Adapt_model_weights_axial.pth\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Web7omXuj7-",
        "outputId": "52625e18-032e-482e-f9f5-253db2335a33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'res_net_axial': 0.6589337060278105, 'res_net_coronal': 0, 'res_net_sagital': 0, 'Alex_net_axial': 0, 'Alex_net_coronal': 0, 'Alex_net_sagital': 0}\n",
            "{'res_net_axial': 0.7838804727459848, 'res_net_coronal': 0, 'res_net_sagital': 0, 'Alex_net_axial': 0, 'Alex_net_coronal': 0, 'Alex_net_sagital': 0}\n"
          ]
        }
      ],
      "source": [
        "# - Evauation Start -\n",
        "log_root_folder = \"./gdrive/MyDrive/assignment/logs/{0}/{1}/\".format(task, plane)\n",
        "\n",
        "now = datetime.now()\n",
        "logdir = log_root_folder + now.strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
        "os.makedirs(logdir)\n",
        "\n",
        "writer = SummaryWriter(logdir)\n",
        "# - Evaluation End -\n",
        "auc_average, acc_average = test(ResNet18Adapt_model,test_loader) # ResNet18Adapt_model, AlexNet_model\n",
        "history_auc['res_net_axial'] = auc_average\n",
        "print(history_auc)\n",
        "history_acc['res_net_axial'] = acc_average\n",
        "print(history_acc)\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWcS8oIlcDPf"
      },
      "source": [
        "Evaluation for ACL tear and Cornal plane"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lS8f0V3Gwii"
      },
      "outputs": [],
      "source": [
        "directory = '/content/gdrive/Shareddrives/MRNet Project/MRNet-v1.0/MRNet-v1.0/'\n",
        "task = 'acl'\n",
        "plane = 'coronal' # Coronal #\n",
        "# initialise the train and validation datasets (class we defined earlier) and then initialise a Pytorch's dataloader\n",
        "test_dataset = Dataset(directory, task, plane, split='test', transform = None)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=-True, num_workers=2, drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IghOVvqNOAB9",
        "outputId": "97730177-70e7-4603-efa5-723ee9b73e0f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ResNet18Adapt_model.load_state_dict(torch.load(\"/content/gdrive/Shareddrives/MRNet Project/model_weights/ResNet18Adapt_model_weights_coronal.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIn5lPRUupHL",
        "outputId": "93093d87-bced-482d-a3f5-4056453d175e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'res_net_axial': 0.6589337060278105, 'res_net_coronal': 0.5, 'res_net_sagital': 0, 'Alex_net_axial': 0, 'Alex_net_coronal': 0, 'Alex_net_sagital': 0}\n",
            "{'res_net_axial': 0.7838804727459848, 'res_net_coronal': 0.8544769850299887, 'res_net_sagital': 0, 'Alex_net_axial': 0, 'Alex_net_coronal': 0, 'Alex_net_sagital': 0}\n"
          ]
        }
      ],
      "source": [
        "# - Evauation Start -\n",
        "log_root_folder = \"./gdrive/MyDrive/assignment/logs/{0}/{1}/\".format(task, plane)\n",
        "\n",
        "now = datetime.now()\n",
        "logdir = log_root_folder + now.strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
        "os.makedirs(logdir)\n",
        "\n",
        "writer = SummaryWriter(logdir)\n",
        "# - Evaluation End -\n",
        "auc_average, acc_average = test(ResNet18Adapt_model,test_loader) # ResNet18Adapt_model, AlexNet_model\n",
        "history_auc['res_net_coronal'] = auc_average\n",
        "print(history_auc)\n",
        "history_acc['res_net_coronal'] = acc_average\n",
        "print(history_acc)\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmpnCSEicGo2"
      },
      "source": [
        "Evaluation for ACL tear and Sagittal plane"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htHJV5REHmwa"
      },
      "outputs": [],
      "source": [
        "directory = '/content/gdrive/Shareddrives/MRNet Project/MRNet-v1.0/MRNet-v1.0/'\n",
        "task = 'acl'\n",
        "plane = 'sagittal' # Coronal #\n",
        "# initialise the train and validation datasets (class we defined earlier) and then initialise a Pytorch's dataloader\n",
        "test_dataset = Dataset(directory, task, plane, split='test', transform = None)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=-True, num_workers=2, drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6Q411tgEpVD",
        "outputId": "0d4efd6e-7dec-4a8f-96e2-d5ca91628193"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ResNet18Adapt_model.load_state_dict(torch.load(\"/content/gdrive/Shareddrives/MRNet Project/model_weights/ResNet18Adapt_model_weights_sagittal.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92OnEI6VEv9r",
        "outputId": "9620ba48-910d-4110-f9fe-761b220fb395"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'res_net_axial': 0.6589337060278105, 'res_net_coronal': 0.5, 'res_net_sagital': 0.9212772947592173, 'Alex_net_axial': 0, 'Alex_net_coronal': 0, 'Alex_net_sagital': 0}\n",
            "{'res_net_axial': 0.7838804727459848, 'res_net_coronal': 0.8544769850299887, 'res_net_sagital': 0.8969074097351194, 'Alex_net_axial': 0, 'Alex_net_coronal': 0, 'Alex_net_sagital': 0}\n"
          ]
        }
      ],
      "source": [
        "# - Evauation Start -\n",
        "log_root_folder = \"./gdrive/MyDrive/assignment/logs/{0}/{1}/\".format(task, plane)\n",
        "\n",
        "now = datetime.now()\n",
        "logdir = log_root_folder + now.strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
        "os.makedirs(logdir)\n",
        "\n",
        "writer = SummaryWriter(logdir)\n",
        "# - Evaluation End -\n",
        "auc_average, acc_average = test(ResNet18Adapt_model,test_loader) # ResNet18Adapt_model, AlexNet_model\n",
        "history_auc['res_net_sagital'] = auc_average\n",
        "print(history_auc)\n",
        "history_acc['res_net_sagital'] = acc_average\n",
        "print(history_acc)\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfcDW4P9cSEX"
      },
      "source": [
        "### AlexNet\n",
        "\n",
        "Evaluation of model with ACL tear and Axial plane"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZLlYhMrHo5N"
      },
      "outputs": [],
      "source": [
        "directory = '/content/gdrive/Shareddrives/MRNet Project/MRNet-v1.0/MRNet-v1.0/'\n",
        "task = 'acl'\n",
        "plane = 'axial' # Coronal #\n",
        "# initialise the train and validation datasets (class we defined earlier) and then initialise a Pytorch's dataloader\n",
        "test_dataset = Dataset(directory, task, plane, split='test', transform = None)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=-True, num_workers=2, drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVd7m37aPD2T",
        "outputId": "1537d18f-7e39-41ee-a283-6f3774d1cc8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "AlexNet_model.load_state_dict(torch.load(\"/content/gdrive/Shareddrives/MRNet Project/model_weights/AlexNet_model_Axial_ACL_weights.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90uzGHJOFxyC",
        "outputId": "5bee6083-3f59-4acb-e1b9-498987a9e0d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'res_net_axial': 0.6589337060278105, 'res_net_coronal': 0.5, 'res_net_sagital': 0.9212772947592173, 'Alex_net_axial': 0.5, 'Alex_net_coronal': 0, 'Alex_net_sagital': 0}\n",
            "{'res_net_axial': 0.7838804727459848, 'res_net_coronal': 0.8544769850299887, 'res_net_sagital': 0.8969074097351194, 'Alex_net_axial': 0.857363525712419, 'Alex_net_coronal': 0, 'Alex_net_sagital': 0}\n"
          ]
        }
      ],
      "source": [
        "# - Evauation Start -\n",
        "log_root_folder = \"./gdrive/MyDrive/assignment/logs/{0}/{1}/\".format(task, plane)\n",
        "\n",
        "now = datetime.now()\n",
        "logdir = log_root_folder + now.strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
        "os.makedirs(logdir)\n",
        "\n",
        "writer = SummaryWriter(logdir)\n",
        "# - Evaluation End -\n",
        "auc_average, acc_average = test(AlexNet_model,test_loader) # ResNet18Adapt_model, AlexNet_model\n",
        "history_auc['Alex_net_axial'] = auc_average\n",
        "print(history_auc)\n",
        "history_acc['Alex_net_axial'] = acc_average\n",
        "print(history_acc)\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t33lqbMScb0D"
      },
      "source": [
        "Evaluation of model with ACL tear and Sagittal plane"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C74te7PSFDX_"
      },
      "outputs": [],
      "source": [
        "directory = '/content/gdrive/Shareddrives/MRNet Project/MRNet-v1.0/MRNet-v1.0/'\n",
        "task = 'acl'\n",
        "plane = 'sagittal' # Coronal #\n",
        "# initialise the train and validation datasets (class we defined earlier) and then initialise a Pytorch's dataloader\n",
        "test_dataset = Dataset(directory, task, plane, split='test', transform = None)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=-True, num_workers=2, drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvASdV4uFDuJ",
        "outputId": "45e66a90-263c-4254-f131-c8b187ecf2ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "AlexNet_model.load_state_dict(torch.load(\"/content/gdrive/Shareddrives/MRNet Project/model_weights/AlexNet_model_weights_sagittal.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuqSOcd7FDuK",
        "outputId": "fc7e0f0f-9974-4a09-9dea-2f67e472830d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'res_net_axial': 0.6589337060278105, 'res_net_coronal': 0.5, 'res_net_sagital': 0.9212772947592173, 'Alex_net_axial': 0.5, 'Alex_net_coronal': 0, 'Alex_net_sagital': 0.5}\n",
            "{'res_net_axial': 0.7838804727459848, 'res_net_coronal': 0.8544769850299887, 'res_net_sagital': 0.8969074097351194, 'Alex_net_axial': 0.857363525712419, 'Alex_net_coronal': 0, 'Alex_net_sagital': 0.8516101908502639}\n"
          ]
        }
      ],
      "source": [
        "# - Evauation Start -\n",
        "log_root_folder = \"./gdrive/MyDrive/assignment/logs/{0}/{1}/\".format(task, plane)\n",
        "\n",
        "now = datetime.now()\n",
        "logdir = log_root_folder + now.strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
        "os.makedirs(logdir)\n",
        "\n",
        "writer = SummaryWriter(logdir)\n",
        "# - Evaluation End -\n",
        "auc_average, acc_average = test(AlexNet_model,test_loader) # ResNet18Adapt_model, AlexNet_model\n",
        "history_auc['Alex_net_sagital'] = auc_average\n",
        "print(history_auc)\n",
        "history_acc['Alex_net_sagital'] = acc_average\n",
        "print(history_acc)\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7GwBsA3cff6"
      },
      "source": [
        "Evaluation of model with ACL tear and Coronal plane"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLRG0PIqFEvy"
      },
      "outputs": [],
      "source": [
        "directory = '/content/gdrive/Shareddrives/MRNet Project/MRNet-v1.0/MRNet-v1.0/'\n",
        "task = 'acl'\n",
        "plane = 'coronal' # Coronal #\n",
        "# initialise the train and validation datasets (class we defined earlier) and then initialise a Pytorch's dataloader\n",
        "test_dataset = Dataset(directory, task, plane, split='test', transform = None)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=-True, num_workers=2, drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLy2zFLKFFCR",
        "outputId": "37a58722-0a42-493f-fb74-f2f77b95a44b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "AlexNet_model.load_state_dict(torch.load(\"/content/gdrive/Shareddrives/MRNet Project/model_weights/AlexNet_model_weights_coronal.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntfzpvjrFFCS",
        "outputId": "ed8e42dd-1bc4-453b-bc94-574e8036576b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'res_net_axial': 0.6589337060278105, 'res_net_coronal': 0.5, 'res_net_sagital': 0.9212772947592173, 'Alex_net_axial': 0.5, 'Alex_net_coronal': 0.5, 'Alex_net_sagital': 0.5}\n",
            "{'res_net_axial': 0.7838804727459848, 'res_net_coronal': 0.8544769850299887, 'res_net_sagital': 0.8969074097351194, 'Alex_net_axial': 0.857363525712419, 'Alex_net_coronal': 0.8748395876020522, 'Alex_net_sagital': 0.8516101908502639}\n"
          ]
        }
      ],
      "source": [
        "# - Evauation Start -\n",
        "log_root_folder = \"./gdrive/MyDrive/assignment/logs/{0}/{1}/\".format(task, plane)\n",
        "\n",
        "now = datetime.now()\n",
        "logdir = log_root_folder + now.strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
        "os.makedirs(logdir)\n",
        "\n",
        "writer = SummaryWriter(logdir)\n",
        "# - Evaluation End -\n",
        "auc_average, acc_average = test(AlexNet_model,test_loader) # ResNet18Adapt_model, AlexNet_model\n",
        "history_auc['Alex_net_coronal'] = auc_average\n",
        "print(history_auc)\n",
        "history_acc['Alex_net_coronal'] = acc_average\n",
        "print(history_acc)\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5-wIHtVV8_o"
      },
      "source": [
        "Insert this snippet into browser developer tools console to ensure that colab runtime does not disconnect.\n",
        "\n",
        "`Note: This does not go against the ToS of Google Colab`\n",
        "\n",
        "```python\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document\n",
        "  .querySelector('#top-toolbar > colab-connect-button')\n",
        "  .shadowRoot.querySelector('#connect')\n",
        "  .click()\n",
        "}\n",
        "setInterval(ClickConnect,60000)\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
